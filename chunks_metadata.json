[
  {
    "type": "text",
    "page": 1,
    "content": "(12) United States Patent \nPage \nUSOO6285999B1 \n(10) Patent No.: \nUS 6,285,999 B1 \n(45) Date of Patent: \nSep. 4, 2001 \n(54) METHOD FOR NODE RANKING INA \nLINKED DATABASE \n(75) Inventor: Lawrence Page, Stanford, CA (US) \n(73) Assignee: The Board of Trustees of the Leland \nStanford Junior University, Stanford, \nCA (US) \n(*) Notice: \nSubject to any disclaimer, the term of this \npatent is extended or adjusted under 35 \nU.S.C. 154(b) by 0 days. \n(21) Appl. No.: 09/004,827 \n(22) Filed: \nJan. 9, 1998 \nRelated U.S. Application Data \n(60) Provisional application No. 60/035,205, filed on Jan. 10, \n1997. \n(51) Int. Cl.\" .................................................. G06F 17/30 \n(52) U.S. Cl. .................................... 707/5; 707/7, 707/501 \n(58) Field of Search .................................... 707/100, 5, 7, \n707/513, 1–3, 10, 104, 501; 345/440, 382/226, \n229, 230, 231 \n(56) \nReferences Cited \nU.S. PATENT DOCUMENTS \n4,953,106 * \n5,450,535 * \n8/1990 Gansner et al. ..................... 345/440 \n9/1995 North ................ \n... 395/140 \n... 395/610 \n5,748,954 \n5/1998 Mauldin .... \n5,752,241 * 5/1998 Cohen ........... \n... 707/3 \n5,832,494 * 11/1998 Egger et al. ...... \n707/102 \n5,848,407 \n12/1998 Ishikawa et al. ........................ 707/2 \n6,014,678 \n1/2000 Inoue et al. .......................... 707/501 \nOTHER PUBLICATIONS \nS. Jeromy Carriere et al., “Web Query: Searching and Visu \nalizing the Web through Connectivity”, Computer Networks \nand ISDN Systems 29 (1997). pp. 1257–1267.* \nWang et al\"Prefetching in Worl WideWeb\", IEEE 1996, pp. \n28-32. \nRamer et al. “Similarity, Probability and Database Organi \nsation: Extended Abstract”, 1996, pp. 272.276.* \nCraig Boyle “To link or not to link: An empirical comparison \nof Hypertext linking strategies”. ACM 1992, pp. 221-231.* \nL. Katz, \"A new Status indeX derived from Sociometric \nanalysis,” 1953, Psychometricka, vol. 18, pp.39-43. \nC.H. Hubbell, “An input-output approach to clique identi \nfication sociometry,” 1965, pp. 377–399. \nMizruchi et al., “Techniques for disaggregating centrality \nscores in Social networks,” 1996, Sociological Methodology, \npp. 26-48. \nE. Garfield, “Citation analysis as a tool in journal evalua \ntion,” 1972, Science, vol. 178, pp. 471-479. \nPinski et al., “Citation influence for journal aggregates of \nScientific publications: Theory, with application to the lit \nerature of physics,” 1976, Inf. Proc. And Management, vol. \n12, pp. 297-312. \nN. Geller, “On the citation influence methodology of Pinski \nand Narin,” 1978, Inf. Proc. And Management, vol. 14, pp. \n93-95. \nP. Doreian, “Measuring the relative Standing of disciplinary \njournals,” 1988, Inf. Proc. And Management, vol. 24, pp. \n45-56. \n(List continued on next page.) \nPrimary Examiner Thomas Black \nAssistant Examiner Uyen Le \n(74) Attorney, Agent, or Firm-Harrity & Snyder L.L.P. \n(57) \nABSTRACT \nA method assigns importance ranks to nodes in a linked \ndatabase, Such as any database of documents containing \ncitations, the World wide web or any other hypermedia \ndatabase. The rank assigned to a document is calculated \nfrom the ranks of documents citing it. In addition, the rank \nof a document is calculated from a constant representing the \nprobability that a browser through the database will ran \ndomly jump to the document. The method is particularly \nuseful in enhancing the performance of Search engine results \nfor hypermedia databases, Such as the World wide web, \nwhose documents have a large variation in quality. \n29 Claims, 3 Drawing Sheets"
  },
  {
    "type": "text",
    "page": 2,
    "content": "US 6,285,999 B1 \nPage 2 \nOTHER PUBLICATIONS \nP. Doreian, “A measure of Standing for citation networks \nwithin a wider environment,” 1994, Inf. Proc. And Manage \nment, vol. 30, pp. 21-31. \nBotafogo et al., \"Structural analysis of hypertext: Identifying \nhierarchies and useful metrics.” 1992, ACM Trans. Inc. \nSystems, vol. 10, pp. 142-180. \nMark E. Frisse, “Searching for information in a hypertext \nmedical handbook,” 1988, Communications of the ACM, \nvol. 31, No. 7, pp. 880-886. \nMassimo Marchiori, “The quest for correct information on \nthe Web: Hyper search engines,” 1997, Computer Networks \nand ISDN Systems, vol. 29, No. 8-13, pp. 1225–1235. \nOliver A. McBryan, “GENVL and WWWW: Tools for \ntaming the web,” 1994, Proceedings of the first International \nWold Wide Web Conference, pp. 1-13. \nCarriere et al., “WebOuery: Searching and visualizing the \nweb through connectivity.” 1997, Proc. 6' International \nWorld Wide Web Conference, pp. 1-14. \nArocena et al., “Applications of a web query language,” \n1997, Computer Networks and ISDN Systems, vol. 29, No. \n8-13, pp. 1305–1316. \nJon M. Kleinberg, “Authoritative sources in a hyperlinked \nenvironment,” 1998, Proc. Of the 9\" Annual ACM-SIAM \nSymposium on Discrete Algorithms, pp. 668-677. \nHenzinger et al., “Measuring indeX quality using random \nwalks on the web”, 1999, Proc. of the 8' International World \nWide Web Conference, pp. 213–225. \n* cited by examiner"
  },
  {
    "type": "text",
    "page": 3,
    "content": "U.S. Patent \nSep. 4, 2001 \nSheet 1 of 3 \nUS 6,285,999 B1 \nA N \nFIG. 1"
  },
  {
    "type": "image",
    "page": 3,
    "content": "extracted_images\\page_3_img_1.png"
  },
  {
    "type": "text",
    "page": 4,
    "content": "U.S. Patent \nSep. 4, 2001 \nSheet 2 of 3 \nUS 6,285,999 B1 \nFIG. 2"
  },
  {
    "type": "image",
    "page": 4,
    "content": "extracted_images\\page_4_img_1.png"
  },
  {
    "type": "text",
    "page": 5,
    "content": "U.S. Patent \nSep. 4, 2001 \nSheet 3 of 3 \nUS 6,285,999 B1 \nSTART \n101 \nSELECT AN INITIALN-DIMENSIONAL VECTOR p, \n103 \nCOMPUTE AN APPROXIMATION p, TO A \nSTEADY-STATE PROBABILITY p. IN \nACCORDANCE WITH THE EQUATION p = Ap, \n105 \nDETERMINEARANKrk FOR NODEk FROMA \nkth COMPONENT OF p. \nDONE \nFIG. 3"
  },
  {
    "type": "image",
    "page": 5,
    "content": "extracted_images\\page_5_img_1.png"
  },
  {
    "type": "text",
    "page": 6,
    "content": "US 6,285,999 B1 \n1 \nMETHOD FOR NODE RANKING IN A \nLINKED DATABASE \nCROSS-REFERENCES TO RELATED \nAPPLICATIONS \nThis application claims priority from U.S. provisional \npatent application Ser. No. 60/035,205 filed Jan. 10, 1997, \nwhich is incorporated herein by reference. \nSTATEMENT REGARDING GOVERNMENT \nSUPPORT \nThis invention was supported in part by the National \nScience Foundation grant number IRI-9411306-4. The Gov \nernment has certain rights in the invention. \nFIELD OF THE INVENTION \nThis invention relates generally to techniques for analyZ \ning linked databases. More particularly, it relates to methods \nfor assigning ranks to nodes in a linked database, Such as any \ndatabase of documents containing citations, the World wide \nweb or any other hypermedia database. \nBACKGROUND OF THE INVENTION \nDue to the developments in computer technology and its \nincrease in popularity, large numbers of people have recently \nStarted to frequently Search huge databases. For example, \ninternet Search engines are frequently used to Search the \nentire World wide Web. Currently, a popular Search engine \nmight execute over 30 million Searches per day of the \nindexable part of the web, which has a size in excess of 500 \nGigabytes. Information retrieval Systems are traditionally \njudged by their precision and recall. What is often neglected, \nhowever, is the quality of the results produced by these \nSearch engines. Large databases of documents Such as the \nweb contain many low quality documents. As a result, \nSearches typically return hundreds of irrelevant or unwanted \ndocuments which camouflage the few relevant ones. In order \nto improve the Selectivity of the results, common techniques \nallow the user to constrain the Scope of the Search to a \nSpecified Subset of the database, or to provide additional \nSearch terms. These techniques are most effective in cases \nwhere the database is homogeneous and already classified \ninto Subsets, or in cases where the user is Searching for well \nknown and Specific information. In other cases, however, \nthese techniques are often not effective because each con \nStraint introduced by the user increases the chances that the \ndesired information will be inadvertently eliminated from \nthe Search results. \nSearch engines presently use various techniques that \nattempt to present more relevant documents. Typically, \ndocuments are ranked according to variations of a Standard \nvector Space model. These variations could include (a) how \nrecently the document was updated, and/or (b) how close the \nSearch terms are to the beginning of the document. Although \nthis Strategy provides Search results that are better than with \nno ranking at all, the results Still have relatively low quality. \nMoreover, when Searching the highly competitive web, this \nmeasure of relevancy is Vulnerable to \"spamming” tech \nniques that authors can use to artificially inflate their docu \nment's relevance in order to draw attention to it or its \nadvertisements. For this reason Search results often contain \ncommercial appeals that should not be considered a match to \nthe query. Although Search engines are designed to avoid \nSuch ruses, poorly conceived mechanisms can result in \ndisappointing failures to retrieve desired information. \n1O \n15 \n25 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n2 \nHyperlink Search Engine, developed by IDD Information \nServices, (http://rankdex.gari.com/) uses backlink informa \ntion (i.e., information from pages that contain links to the \ncurrent page) to assist in identifying relevant web docu \nments. Rather than using the content of a document to \ndetermine relevance, the technique uses the anchor text of \nlinks to the document to characterize the relevance of a \ndocument. The idea of associating anchor text with the page \nthe text points to was first implemented in the World Wide \nWeb Worm (Oliver A. McBryan, GENVL and WWWW: \nTools for Taming the Web, First International Conference on \nthe World Wide Web, CERN, Geneva, May 25–27, 1994). \nThe Hyperlink Search Engine has applied this idea to assist \nin determining document relevance in a Search. In particular, \nSearch query terms are compared to a collection of anchor \ntext descriptions that point to the page, rather than to a \nkeyword index of the page content. A rank is then assigned \nto a document based on the degree to which the Search terms \nmatch the anchor descriptions in its backlink documents. \nThe well known idea of citation counting is a simple \nmethod for determining the importance of a document by \ncounting its number of citations, or backlinkS. The citation \nrank r(A) of a document which has n backlink pages is \nSimply \nIn the case of databases whose content is of relatively \nuniform quality and importance it is valid to assume that a \nhighly cited document should be of greater interest than a \ndocument with only one or two citations. Many databases, \nhowever, have eXtreme variations in the quality and impor \ntance of documents. In these cases, citation ranking is overly \nSimplistic. For example, citation ranking will give the same \nrank to a document that is cited once on an obscure page as \nto a similar document that is cited once on a well-known and \nhighly respected page. \nSUMMARY \nVarious aspects of the present invention provide Systems \nand methods for ranking documents in a linked database. \nOne aspect provides an objective ranking based on the \nrelationship between documents. Another aspect of the \ninvention is directed to a technique for ranking documents \nwithin a database whose content has a large variation in \nquality and importance. Another aspect of the present inven \ntion is to provide a document ranking method that is Scalable \nand can be applied to extremely large databaseS Such as the \nworld wide web. Additional aspects of the invention will \nbecome apparent in View of the following description and \nasSociated figures. \nOne aspect of the present invention is directed to taking \nadvantage of the linked Structure of a database to assign a \nrank to each document in the database, where the document \nrank is a measure of the importance of a document. Rather \nthan determining relevance only from the intrinsic content of \na document, or from the anchor text of backlinks to the \ndocument, a method consistent with the invention deter \nmines importance from the extrinsic relationships between \ndocuments. Intuitively, a document should be important \n(regardless of its content) if it is highly cited by other \ndocuments. Not all citations, however, are necessarily of \nequal Significance. A citation from an important document is \nmore important than a citation from a relatively unimportant \ndocument. Thus, the importance of a page, and hence the \nrank assigned to it, should depend not just on the number of \ncitations it has, but on the importance of the citing docu \nments as well. This implies a recursive definition of rank: the"
  },
  {
    "type": "text",
    "page": 7,
    "content": "US 6,285,999 B1 \n3 \nrank of a document is a function of the ranks of the \ndocuments which cite it. The ranks of documents may be \ncalculated by an iterative procedure on a linked database. \nBecause citations, or links, are ways of directing \nattention, the important documents correspond to those \ndocuments to which the most attention is directed. Thus, a \nhigh rank indicates that a document is considered valuable \nby many people or by important people. Most likely, these \nare the pages to which Someone performing a Search would \nlike to direct his or her attention. Looked at another way, the \nimportance of a page is directly related to the Steady-state \nprobability that a random Web Surfer ends up at the page \nafter following a large number of linkS. Because there is a \nlarger probability that a Surfer will end up at an important \npage than at an unimportant page, this method of ranking \npages assigns higher ranks to the more important pages. \nIn one aspect of the invention, a computer implemented \nmethod is provided for Scoring linked database documents. \nThe method comprises the Steps of \nobtaining a plurality of documents, at least Some of the \ndocuments being linked documents, at least Some of the \ndocuments being linking documents, and at least Some \nof the documents being both linked documents and \nlinking documents, each of the linked documents being \npointed to by a link in one or more of the linking \ndocuments, assigning a Score to each of the linked \ndocuments based on Scores of the one or more linking \ndocuments, and processing the linked documents \naccording to their Scores. \nAdditional aspects, applications and advantages will \nbecome apparent in View of the following description and \nasSociated figures. \nBRIEF DESCRIPTION OF THE DRAWINGS \nFIG. 1 is a diagram of the relationship between three \nlinked hypertext documents according to the invention. \nFIG. 2 is a diagram of a three-document web illustrating \nthe rank associated with each document in accordance with \nthe present invention. \nFIG. 3 is a flowchart of one embodiment of the invention. \nDETAILED DESCRIPTION \nAlthough the following detailed description contains \nmany specifics for the purposes of illustration, anyone of \nordinary skill in the art will appreciate that many variations \nand alterations to the following details are within the Scope \nof the invention. Accordingly, the following embodiments of \nthe invention are Set forth without any loSS of generality to, \nand without imposing limitations upon, the claimed inven \ntion. For Support in reducing the present invention to \npractice, the inventor acknowledges Sergey Brin, Scott \nHassan, Rajeev Motwani, Alan Steremberg, and Terry Wino \ngrad. \nA linked database (i.e. any database of documents con \ntaining mutual citations, Such as the Worldwide web or other \nhypermedia archive, a dictionary or thesaurus, and a data \nbase of academic articles, patents, or court cases) can be \nrepresented as a directed graph of N nodes, where each node \ncorresponds to a web page document and where the directed \nconnections between nodes correspond to links from one \ndocument to another. A given node has a set of forward links \nthat connect it to children nodes, and a set of backward links \nthat connect it to parent nodes. FIG. 1 shows a typical \nrelationship between three hypertext documents A, B, and C. \nAS shown in this particular figure, the first linkS in docu \n15 \n25 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n4 \nments B and C are pointers to document A. In this case we \nsay that B and C are backlinks of A, and that A is a forward \nlink of B and of C. Documents B and C also have other \nforward links to documents that are not shown. \nAlthough the ranking method of the present invention is \nSuperficially similar to the well known idea of citation \ncounting, the present method is more Subtle and complex \nthan citation counting and gives far Superior results. In a \nSimple citation ranking, the rank of a document A which has \nin backlink pages is simply \nAccording to one embodiment of the present method of \nranking, the backlinks from different pages are weighted \ndifferently and the number of links on each page is normal \nized. More precisely, the rank of a page A is defined \naccording to the present invention as \nr(B1) -- \nB1 \nr(B) ) \nC \nr(A) = + (1-0) \n* IBT): \nwhere B, ..., B, are the backlink pages of A, r(B), ..., \nr(B) are their ranks, B, . . . , B, are their numbers of \nforward links, and C. is a constant in the interval 0,1, and \nN is the total number of pages in the web. This definition is \nclearly more complicated and Subtle than the Simple citation \nrank. Like the citation rank, this definition yields a page rank \nthat increases as the number of backlinks increases. But the \npresent method considers a citation from a highly ranked \nbacklink as more important than a citation from a lowly \nranked backlink (provided both citations come from back \nlink documents that have an equal number of forward links). \nIn the present invention, it is possible, therefore, for a \ndocument with only one backlink (from a very highly ranked \npage) to have a higher rank than another document with \nmany backlinks (from very low ranked pages). This is not \nthe case with Simple citation ranking. \nThe ranks form a probability distribution over web pages, \nSo that the Sum of ranks over all web pages is unity. The rank \nof a page can be interpreted as the probability that a Surfer \nwill be at the page after following a large number of forward \nlinks. The constant C. in the formula is interpreted as the \nprobability that the web surfer will jump randomly to any \nweb page instead of following a forward link. The page \nranks for all the pages can be calculated using a simple \niterative algorithm, and corresponds to the principal eigen \nvector of the normalized link matrix of the web, as will be \ndiscussed in more detail below. \nIn order to illustrate the present method of ranking, \nconsider the simple web of three documents shown in FIG. \n2. For Simplicity of illustration, we assume in this example \nthat r=0. Document A has a Single backlink to document C, \nand this is the only forward link of document C, so \nr(A)=r(C). \nDocument B has a Single backlink to document A, but this \nis one of two forward links of document A, SO \nr(B)=r(A)/2. \nDocument C has two backlinks. One backlink is to \ndocument B, and this is the only forward link of document \nB. The other backlink is to document A via the other of the \ntwo forward links from A. Thus \nr(C)=r(B)+r(A)/2. \nIn this simple illustrative case we can see by inspection \nthat r(A)=0.4, r(B)=0.2, and r(C)=0.4. Although a typical \nvalue for C. is -0.1, if for simplicity we set C =0.5 (which \ncorresponds to a 50% chance that a Surfer will randomly \njump to one of the three pages rather than following a"
  },
  {
    "type": "text",
    "page": 8,
    "content": "US 6,285,999 B1 \nS \nforward link), then the mathematical relationships between \nthe ranks become more complicated. In particular, we then \nhave \nThe solution in this case is r(A)=1%9, r(B)=1%9, and \nr(C)=1549. \nIn practice, there are millions of documents and it is not \npossible to find the Solution to a million equations by \ninspection. Accordingly, in the preferred embodiment a \nSimple iterative procedure is used. AS the initial State we \nmay simply Set all the ranks equal to 1/N. The formulas are \nthen used to calculate a new set of rankS based on the \nexisting ranks. In the case of millions of documents, Suffi \ncient convergence typically takes on the order of 100 itera \ntions. It is not always necessary or even desirable, however, \nto calculate the rank of every page with high precision. Even \napproximate rank values, using two or more iterations, can \nprovide very valuable, or even Superior, information. \nThe iteration proceSS can be understood as a steady-state \nprobability distribution calculated from a model of a random \nSurfer. This model is mathematically equivalent to the expla \nnation described above, but provides a more direct and \nconcise characterization of the procedure. The model \nincludes (a) an initial N-dimensional probability distribution \nvector po where each component poil gives the initial \nprobability that a random Surfer will start at a node i, and (b) \nan NxN transition probability matrix A where each compo \nnent Aij gives the probability that the surfer will move \nfrom node i to node j. The probability distribution of the \ngraph after the Surfer follows one link is p=Apo, and after \ntwo links the probability distribution is p=Ap=Ap'. \nASSuming this iteration converges, it will converge to a \nSteady-state probability \npea = lim. Apo, \nwhich is a dominant eigenvector of A. The iteration circu \nlates the probability through the linked nodes like energy \nflows through a circuit and accumulates in important places. \nBecause pages with no links occur in Significant numbers \nand bleed off energy, they cause Some complication with \ncomputing the ranking. This complication is caused by the \nfact they can add huge amounts to the \"random jump' factor. \nThis, in turn, causes loops in the graph to be highly empha \nsized which is not generally a desirable property of the \nmodel. In order to address this problem, these childless \npages can Simply be removed from the model during the \niterative Stages, and added back in after the iteration is \ncomplete. After the childless pages are added back in, \nhowever, the same number of iterations that was required to \nremove them should be done to make Sure they all receive \na value. (Note that in order to ensure convergence, the norm \nof p must be made equal to 1 after each iteration.) An \nalternate method to control the contribution of the childless \nnodes is to only estimate the Steady State by iterating a Small \nnumber of times. \nThe rank ri) of a node i can then be defined as a function \nof this steady-state probability distribution. For example, the \nrank can be defined simply by ri=pooi. This method of \ncalculating rank is mathematically equivalent to the iterative \nmethod described first. Those skilled in the art will appre \nciate that this same method can be characterized in various \ndifferent ways that are mathematically equivalent. Such \ncharacterizations are obviously within the Scope of the \n15 \n25 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n6 \npresent invention. Because the rank of various different \ndocuments can vary by orders of magnitude, it is convenient \nto define a logarithmic rank \npei \nri) = log- \n{pok: \nPeo \nke 1, N \nwhich assigns a rank of 0 to the lowest ranked node and \nincreases by 1 for each order of magnitude in importance \nhigher than the lowest ranked node. \n“FIG. 3 shows one embodiment of a computer imple \nmented method for calculating an importance rank for N \nlinked nodes of a linked database. At a step 101, an initial \nN-dimensional vector po is Selected. An approximation p, to \na steady-state probability p in accordance with the equation \np=A\"po is computed at a step 103. Matrix A can be an NXN \ntransition probability matrix having elements Ai \nrepre \nSenting a probability of moving from node i to node j. At a \nstep 105, a rank rk) for node k from a k\" component of p, \nis determined.”. \nIn one particular embodiment, a finite number of itera \ntions are performed to approximate poo. The initial distri \nbution can be Selected to be uniform or non-uniform. A \nuniform distribution would set each component of p equal \nto 1/N. A non-uniform distribution, for example, can divide \nthe initial probability among a few nodes which are known \na priori to have relatively large importance. This non \nuniform distribution decreases the number of iterations \nrequired to obtain a close approximation to poo and also is \none way to reduce the effect of artificially inflating relevance \nby adding unrelated terms. \nIn another particular embodiment, the transition matrix A \nis given by \nA = 1 + (1 - a B \n= 1 + (1-0)B. \nwhere 1 is an NxN matrix consisting of all 1s., C. is the \nprobability that a Surfer will jump randomly to any one \nof the N nodes, and B is a matrix whose elements \nBij are given by \n1 \n- if node i points to node i \nBij = n; \n0 otherwise, \nwhere n is the total number of forward links from node \ni. The (1-C) factor acts as a damping factor that \nlimits the extent to which a document's rank can be \ninherited by children documents. This models the \nfact that users typically jump to a different place in \nthe web after following a few links. The value of C. \nis typically around 15%. Including this damping is \nimportant when many iterations are used to calculate \nthe rank So that there is no artificial concentration of \nrank importance within loops of the web. \nAlternatively, one may set C=0 and only iterate a few \ntimes in the calculation. \nConsistent with the present invention, there are Several \nways that this method can be adapted or altered for various \npurposes. AS already mentioned above, rather than including \nthe random linking probability C. equally among all nodes, \nit can be divided in various ways among all the Sites by \nchanging the 1 matrix to another matrix. For example, it \ncould be distributed So that a random jump takes the Surfer"
  },
  {
    "type": "text",
    "page": 9,
    "content": "US 6,285,999 B1 \n7 \nto one of a few nodes that have a high importance, and will \nnot take the surfer to any of the other nodes. This can be very \neffective in preventing deceptively tagged documents from \nreceiving artificially inflated relevance. Alternatively, the \nrandom linking probability could be distributed so that \nrandom jumps do not happen from high importance nodes, \nand only happen from other nodes. This distribution would \nmodel a Surfer who is more likely to make random jumps \nfrom unimportant sites and follow forward links from \nimportant sites. A modification to avoid drawing unwar \nranted attention to pages with artificially inflated relevance \nis to ignore local links between documents and only consider \nlinks between Separate domains. Because the links from \nother Sites to the document are not directly under the control \nof a typical web site designer, it is then difficult for the \ndesigner to artificially inflate the ranking. A simpler \napproach is to weight links from pages contained on the \nSame web server less than links from other Servers. Also, in \naddition to Servers, internet domains and any general mea \nSure of the distance between links could be used to deter \nmine Such a weighting. \nAdditional modifications can further improve the perfor \nmance of this method. Rank can be increased for documents \nwhose backlinks are maintained by different institutions and \nauthors in various geographic locations. Or it can be \nincreased if linkS come from unusually important web \nlocations Such as the root page of a domain. \nLinkS can also be weighted by their relative importance \nwithin a document. For example, highly visible links that are \nnear the top of a document can be given more weight. Also, \nlinks that are in large fonts or emphasized in other ways can \nbe given more weight. In this way, the model better approxi \nmates human usage and authors intentions. In many cases \nit is appropriate to assign higher value to links coming from \npages that have been modified recently Since Such informa \ntion is less likely to be obsolete. \nVarious implementations of the invention have the advan \ntage that the convergence is very fast (a few hours using \ncurrent processors) and it is much less expensive than \nbuilding a full-text index. This Speed allows the ranking to \nbe customized or personalized for Specific users. For \nexample, a user's home page and/or bookmarks can be given \na large initial importance, and/or a high probability of a \nrandom jump returning to it. This high rating essentially \nindicates to the System that the person's homepage and/or \nbookmarks does indeed contain Subjects of importance that \nshould be highly ranked. This procedure essentially trains \nthe System to recognize pages related to the person's inter \nests. The present method of determining the rank of a \ndocument can also be used to enhance the display of \ndocuments. In particular, each link in a document can be \nannotated with an icon, text, or other indicator of the rank of \nthe document that each link points to. Anyone viewing the \ndocument can then easily See the relative importance of \nvarious links in the document. \nThe present method of ranking documents in a database \ncan also be useful for estimating the amount of attention any \ndocument receives on the Web Since it models human \nbehavior when Surfing the Web. Estimating the importance \nof each backlink to a page can be useful for many purposes \nincluding Site design, busineSS arrangements with the \nbacklinkers, and marketing. The effect of potential changes \nto the hypertext Structure can be evaluated by adding them \nto the link Structure and recomputing the ranking. \nReal usage data, when available, can be used as a starting \npoint for the model and as the distribution for the alpha \nfactor. \n15 \n25 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n8 \nThis can allow this ranking model to fill holes in the usage \ndata, and provide a more accurate or comprehensive picture. \nThus, although this method of ranking does not necessar \nily match the actual traffic, it nevertheless measures the \ndegree of exposure a document has throughout the web. \nAnother important application and embodiment of the \npresent invention is directed to enhancing the quality of \nresults from Web Search engines. In this application of the \npresent invention, a ranking method according to the inven \ntion is integrated into a web search engine to produce results \nfar Superior to existing methods in quality and performance. \nA Search engine employing a ranking method of the present \ninvention provides automation while producing results com \nparable to a human maintained categorized System. In this \napproach, a web crawler explores the web and creates an \nindex of the web content, as well as a directed graph of \nnodes corresponding to the Structure of hyperlinks. The \nnodes of the graph (i.e. pages of the web) are then ranked \naccording to importance as described above in connection \nwith various exemplary embodiments of the present inven \ntion. \nThe Search engine is used to locate documents that match \nthe Specified Search criteria, either by Searching full text, or \nby Searching titles only. In addition, the Search can include \nthe anchor text associated with backlinks to the page. This \napproach has Several advantages in this context. First, \nanchors often provide more accurate descriptions of web \npages than the pages themselves. Second, anchors may exist \nfor images, programs, and other objects that cannot be \nindexed by a text-based Search engine. This also makes it \npossible to return web pages which have not actually been \ncrawled. In addition, the engine can compare the Search \nterms with a list of its backlink document titles. Thus, even \nthough the text of the document itself may not match the \nSearch terms, if the document is cited by documents whose \ntitles or backlink anchor text match the Search terms, the \ndocument will be considered a match. In addition to or \ninstead of the anchor text, the text in the immediate vicinity \nof the backlink anchor text can also be compared to the \nSearch terms in order to improve the Search. \nOnce a set of documents is identified that match the Search \nterms, the list of documents is then Sorted with high ranking \ndocuments first and low ranking documents last. The rank \ning in this case is a function which combines all of the above \nfactorS Such as the objective ranking and textual matching. \nIf desired, the results can be grouped by category or Site as \nwell. \nIt will be clear to one skilled in the art that the above \nembodiments may be altered in many ways without depart \ning from the Scope of the invention. Accordingly, the Scope \nof the invention should be determined by the following \nclaims and their legal equivalents. \nWhat is claimed is: \n1. A computer implemented method of Scoring a plurality \nof linked documents, comprising: \nobtaining a plurality of documents, at least Some of the \ndocuments being linked documents, at least Some of the \ndocuments being linking documents, and at least Some \nof the documents being both linked documents and \nlinking documents, each of the linked documents being \npointed to by a link in one or more of the linking \ndocuments, \nassigning a Score to each of the linked documents based \non Scores of the one or more linking documents and \nprocessing the linked documents according to their \nSCOCS."
  },
  {
    "type": "text",
    "page": 10,
    "content": "US 6,285,999 B1 \n9 \n2. The method of claim 1, wherein the assigning includes: \nidentifying a weighting factor for each of the linking \ndocuments, the weighting factor being dependent on \nthe number of links to the one or more linking \ndocuments, and \nadjusting the Score of each of the one or more linking \ndocuments based on the identified weighting factor. \n3. The method of claim 1, wherein the assigning includes: \nidentifying a weighting factor for each of the linking \ndocuments, the weighting factor being dependent on an \nestimation of a probability that a linking document will \nbe accessed, and \nadjusting the Score of each of the one or more linking \ndocuments based on the identified weighting factor. \n4. The method of claim 1, wherein the assigning includes: \nidentifying a weighting factor for each of the linking \ndocuments, the weighting factor being dependent on \nthe URL, host, domain, author, institution, or last \nupdate time of the one or more linking documents, and \nadjusting the Score of each of the one or more linking \ndocuments based on the identified weighting factor. \n5. The method of claim 1, wherein the assigning includes: \nidentifying a weighting factor for each of the linking \ndocuments, the weighting factor being dependent on \nwhether the one or more linking documents are Selected \ndocuments or roots, and \nadjusting the Score of each of the one or more linking \ndocuments based on the identified weighting factor. \n6. The method of claim 1, wherein the assigning includes: \nidentifying a weighting factor for each of the linking \ndocuments, the weighting factor being dependent on \nthe importance, visibility or textual emphasis of the \nlinks in the one or more linking documents, and \nadjusting the Score of each of the one or more linking \ndocuments based on the identified weighting factor. \n7. The method of claim 1, wherein the assigning includes: \nidentifying a weighting factor for each of the linking \ndocuments, the weighting factor being dependent on a \nparticular user's preferences, the rate at which users \naccess the one or more linking documents, or the \nimportance of the one or more linking documents, and \nadjusting the Score of each of the one or more linking \ndocuments based on the identified weighting factor. \n8. A computer implemented method of determining a \nScore for a plurality of linked documents, comprising: \nobtaining a plurality of linked documents, \nSelecting one of the linked documents, \nassigning a Score to the Selected document that is depen \ndent on Scores of documents that link to the Selected \ndocument; and \nprocessing the linked documents according to their \nSCOCS. \n9. A computer implemented method of ranking a plurality \nof linked documents, comprising: \nobtaining a plurality of documents, at least Some of the \ndocuments being linked documents and at least Some of \nthe documents being linking documents, at least Some \nof the linking documents also being linked documents, \neach of the linked documents being pointed to by a link \nin one or more of the linking documents, \ngenerating an initial estimate of a rank for each of the \nlinked documents, \nupdating the estimate of the rank for each of the linked \ndocuments using ranks for the one or more linking \ndocuments, and \n5 \n15 \n25 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n10 \nprocessing the linked documents according to their \nupdated rankS. \n10. A computer implemented method of ranking a plural \nity of linked documents, comprising: \nautomatically performing a random traversal of a plurality \nof linked documents, the random traversal including \nSelecting a random link to traverse in a current linked \ndocument; \nfor each linked document that is traversed, assigning a \nrank to the linked document that is dependent on the \nnumber of times the linked document has been tra \nVersed; and \nprocessing the plurality of linked documents according to \ntheir rank. \n11. The method of claim 10, wherein there is a predeter \nmined probability that the next linked document to be \ntraversed will be a random one according to a distribution of \nthe plurality of linked documents. \n12. The method of claim 1, wherein the processing \nincludes: \ndisplaying links to the linked documents as a directory \nlisting. \n13. The method of claim 1, wherein the processing \nincludes: \ndisplaying links to the linked documents, and \ndisplaying annotations representing the Score of each of \nthe linked documents. \n14. The method of claim 13, wherein the annotations are \nbars, icons, or text. \n15. The method of claim 1, further comprising: \nprocessing the linked documents based on textual match \ning. \n16. The method of claim 15, wherein the textual matching \nincludes matching anchor text associated with the linkS. \n17. The method of claim 1, further comprising: \nprocessing the linked documents based on groupings of \nthe linked documents. \n18. A computer-readable medium that Stores instructions \nexecutable by one or more processing devices to perform a \nmethod for determining Scores for a plurality of linked \ndocuments, comprising: \ninstructions for obtaining a plurality of documents, at \nleast Some of the documents being linked documents, at \nleast Some of the documents being linking documents, \nand at least Some of the documents being both linked \ndocuments and linking documents, each of the linked \ndocuments being pointed to by a link in one or more of \nthe linking documents, \ninstructions for determining a Score for each of the linked \ndocuments based on Scores for the one or more linking \ndocuments, and \ninstructions for processing the linked documents accord \ning to their Scores. \n19. A computer-readable medium that stores instructions \nexecutable by one or more processors to perform a method \nfor Scoring documents, comprising: \ninstructions for Searching a plurality of documents, at \nleast Some of the documents being linked documents \nand at least Some of the documents being linking \ndocuments, at least Some of the linking documents also \nbeing linked documents, each of the linked documents \nbeing pointed to by a link in one or more of the linking \ndocuments, \ninstructions for Scoring each of the linked documents \nbased on Scores for the one or more linking documents, \nand"
  },
  {
    "type": "text",
    "page": 11,
    "content": "US 6,285,999 B1 \n11 \ninstructions for providing the linked documents based on \ntheir Scores. \n20. The method of claim 1, wherein the assigning a Score \nincludes: \ndetermining the score based on (1) a number of the linking \ndocuments that link to the linked document and (2) an \nimportance of the linking documents. \n21. The method of claim 20, wherein the importance of \nthe linking documents is based on a number of documents \nthat link to the linking documents. \n22. The method of claim 1, wherein the assigning a Score \nincludes: \nasSociating one or more backlinks with each of the linked \ndocuments, each of the backlinkS corresponding to one \nof the linking documents that links to the linked \ndocument, \nassigning a weight to each of the backlinks, and \ndetermining a Score for each of the linked documents \nbased on a number of backlinks for the linked docu \nment and the weights assigned to the backlinkS. \n23. The method of claim 22, wherein the processing of the \nlinked documents includes: \norganizing the linked documents based on the determined \nSCOCS. \n24. The method of claim 22, wherein the assigning a \nweight includes: \nassigning different weights to at least Some of the back \nlinks associated with at least one of the linked docu \nmentS. \n5 \n15 \n25 \n12 \n25. The method of claim 1, wherein the assigning a Score \nincludes: \nasSociating one or more backlinks with each of the linked \ndocuments, each of the backlinks corresponding to one \nof the linking documents that links to the linked \ndocument, \nassigning a weight to each of the backlinks, and \ndetermining a Score for each of the linked documents \nbased on a Sum of the weights assigned to the backlinks \nasSociated with the linked document. \n26. The method of claim 25, wherein the weights assigned \nto each of the backlinks are independent of text of the \ncorresponding linking documents. \n27. The method of claim 1, wherein the assigning a Score \nincludes: \ndetermining the Score primarily based on linking infor \nmation. \n28. The method of claim 1, wherein the assigning a Score \nincludes: \ndetermining the Score Substantially independent of user \nquery content. \n29. The method of claim 1, wherein the assigning a Score \nincludes: \niteratively determining the Score for a linked document, \nthe Score being primarily based on document-linking \ninformation and Substantially independent of user \nquery content."
  },
  {
    "type": "text",
    "page": 12,
    "content": "UNITED STATES PATENT AND TRADEMARK OFFICE \nCERTIFICATE OF CORRECTION \nPATENT NO. \n: 6,285,999 B1 \nPage 1 of 1 \nAPPLICATIONNO. \n: 09/004.827 \nDATED \n: September 4, 2001 \nINVENTOR(S) \n: Lawrence Page \nIt is certified that error appears in the above-identified patent and that said Letters Patent is hereby corrected as shown below: \nIn the Specification \nColumn 1, lines 13-15 should be replaced with the following paragraph: \nThis invention was made with Government support under contract 941 1306 awarded by the National \nScience Foundation. The Government has certain rights in this invention. \nSigned and Sealed this \nSixth Day of August, 2013 \nTeresa Stanek Rea \nActing Director of the United States Patent and Trademark Office"
  }
]